{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Run the first 2 code cells without modifications_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1354/1831701278.py:9: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python ver: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:53:32) [GCC 12.3.0]\n",
      "Python env: mcbtest\n",
      "Currrent dir: /home/cat/projects/MCCE_Benchmarking/notebooks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from IPython.display import Markdown #, IFrame\n",
    "# for presentations:\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#pd.set_option(\"display.max_colwidth\", 200)\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "plt.ion()\n",
    "plt.style.use('seaborn-v0_8-muted')\n",
    "from pprint import pprint as ptp\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "print('Python ver: {}\\nPython env: {}'.format(sys.version, Path(sys.prefix).name))\n",
    "print('Currrent dir: {}\\n'.format(Path.cwd()))\n",
    "\n",
    "\n",
    "def add_to_sys_path(this_path, up=False):\n",
    "    \"\"\"\n",
    "    Prepend this_path to sys.path.\n",
    "    If up=True, path refers to parent folder (1 level up).\n",
    "    \"\"\"\n",
    "\n",
    "    if up:\n",
    "        newp = str(Path(this_path).parent)\n",
    "    else:\n",
    "        newp = str(Path(this_path))\n",
    "    if newp not in sys.path:\n",
    "        sys.path.insert(1, newp)\n",
    "        print('Path added to sys.path: {}'.format(newp))\n",
    "\n",
    "\n",
    "def fdir(obj, start_with_str='_', exclude=True):\n",
    "    \"\"\"Filtered dir() for method discovery.\"\"\"\n",
    "    return [d for d in dir(obj) if not d.startswith(start_with_str) == exclude]\n",
    "\n",
    "def despine(which=['top','right']):\n",
    "    \"\"\"which ([str])): 'left','top','right','bottom'.\"\"\"\n",
    "\n",
    "    ax = plt.gca()\n",
    "    for side in which:\n",
    "        ax.spines[side].set_visible(False)\n",
    "    return\n",
    "\n",
    "def md_width_comment(w:int=120) -> str:\n",
    "    \"\"\"Width guide for composing md documents.\"\"\"\n",
    "    return f\"<!-- dotted line width = {w}\\n{'.'*w}-->\"\n",
    "\n",
    "\n",
    "# autoreload extension\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "notebooks_dir = Path.cwd()\n",
    "add_to_sys_path(notebooks_dir, up=True)\n",
    "notebooks_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcce_benchmark import APP_NAME, BENCH\n",
    "from mcce_benchmark import N_BATCH, N_PDBS, ENTRY_POINTS, OUT_FILES, MCCE_OUTPUTS, ANALYZE_DIR, RUNS_DIR\n",
    "\n",
    "from mcce_benchmark import USER_PRFX, USER_ENV, CONDA_PATH\n",
    "from mcce_benchmark import io_utils as iou\n",
    "#from mcce_benchmark import Pathok\n",
    "\n",
    "import subprocess\n",
    "from typing import Union\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(BENCH)\n",
    "print(f\"{USER_PRFX = }\\n{USER_ENV = }\\n{CONDA_PATH = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcce_benchmark import pkanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmarks_dir = PosixPath('/home/cat/projects/bench_tests/all_pdbs')\n",
      "pdbs = PosixPath('/home/cat/projects/bench_tests/all_pdbs/RUNS')\n"
     ]
    }
   ],
   "source": [
    "here = Path.cwd()\n",
    "\n",
    "# completed runs w/analysis:\n",
    "benchmarks_dir = iou.Pathok(Path.cwd().parent.parent.joinpath(\"bench_tests\", \"all_pdbs\"))\n",
    "print(f\"{benchmarks_dir = }\")\n",
    "\n",
    "pdbs = benchmarks_dir.joinpath(RUNS_DIR)\n",
    "print(f\"{pdbs = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched_fp = PosixPath('/home/cat/projects/bench_tests/all_pdbs/analysis/matched_pkas.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'fit': (0.9638685701613313, 1.0),\n",
       " 'N': 1028,\n",
       " 'mean_delta': 1.0635564202334629,\n",
       " 'rmsd': 1.7067523709202879,\n",
       " 'bounds': [3.0, 2.0, 1.0],\n",
       " 'report': 'Residues stats:\\nNumber of pKas matched with those in pKaDB: 1,028\\nFit line: y = 0.96.x + 0.09\\nMean delta pKa: 1.06\\nRMSD, calculated vs experimental: 1.71\\nProportion within 3.0 pH units: 94.55%\\nProportion within 2.0 pH units: 88.13%\\nProportion within 1.0 pH units: 64.88%\\n'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_fp = benchmarks_dir.joinpath(ANALYZE_DIR, OUT_FILES.MATCHED_PKAS.value)\n",
    "print(f\"{matched_fp = }\")\n",
    "\n",
    "matched_df = pkanalysis.load_matched_pkas(matched_fp)\n",
    "matched_stats = pkanalysis.matched_pkas_stats(matched_df)\n",
    "type(matched_stats)\n",
    "matched_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residues stats:\n",
      "Number of pKas matched with those in pKaDB: 1,028\n",
      "Fit line: y = 0.96.x + 0.09\n",
      "Mean delta pKa: 1.06\n",
      "RMSD, calculated vs experimental: 1.71\n",
      "Proportion within 3.0 pH units: 94.55%\n",
      "Proportion within 2.0 pH units: 88.13%\n",
      "Proportion within 1.0 pH units: 64.88%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(matched_stats[\"report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched_stats_fp = PosixPath('/home/cat/projects/bench_tests/all_pdbs/analysis/matched_pkas_stats.json')\n"
     ]
    }
   ],
   "source": [
    "matched_stats_fp = matched_fp.parent.joinpath(OUT_FILES.MATCHED_PKAS_STATS.value)\n",
    "dict_to_json(matched_stats, matched_stats_fp)\n",
    "print(f\"{matched_stats_fp = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_stats_fromjson = json_to_dict(matched_stats_fp)\n",
    "type(matched_stats_fromjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpt = report_matched_stats(matched_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residues statistics:\n",
      "fit: (0.96, 1.0)\n",
      "N: 1028\n",
      "mean_delta: 1.06\n",
      "rmsd: 1.71\n",
      "bounds: [3.0, 2.0, 1.0]\n",
      "txt: Residues stats:\n",
      "Number of pKas matched with those in pKaDB: 1,028\n",
      "Fit line: y = 0.96.x + 0.09\n",
      "Mean delta pKa: 1.06\n",
      "RMSD, calculated vs experimental: 1.71\n",
      "Proportion within 3.0 pH units: 94.55%\n",
      "Proportion within 2.0 pH units: 88.13%\n",
      "Proportion within 1.0 pH units: 64.88%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Refset prep:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "---\n",
    "\n",
    "# prep download copy of completed refset from isis; keep pK.out until pkanalysis run on folder\n",
    "\n",
    "```\n",
    "total 184\r\n",
    "-rw-r--r--   1 cat cat 173762 Feb 16 10:08 WT_pkas.csv\r\n",
    "-rw-r--r--   1 cat cat    483 Feb 16 10:13 benchmark.log\r\n",
    "drwxr-xr-x 122 cat cat   4096 Feb 16 10:13 clean_pdbs\r\n",
    "-rw-r--r--   1 cat cat   2763 Feb 16 10:08 proteins\n",
    "```\n",
    "# cleanup of mcce_benchmarks copy from isis:\r\n",
    "\r\n",
    "1. get\r\n",
    "scp -r cchenal@134.74.25.124/:~projects/mcce_benchm\n",
    "arks/ .m t files exceptbe  kept:\r\n",
    "  -rucn.prm. rord\r\n",
    "  -  run.lp2_out.pdb\n",
    "  - new.tpl oprot.tpl  ave43 pr\n",
    " h\n",
    "  one)    - pK.out :: until anal\n",
    "ison():.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Use jmao's benchmark folder as testing data\n",
    "0. Rename clean_pdb/ -> clean_pdbs/            [x]\n",
    "1. get list of full runs                       [x]\n",
    "(base) cat@LABTOP:~/projects/benchmark$\n",
    "find clean_pdbs/*/ -type f -name \"pK.out\"\n",
    "\n",
    "2. match dir & copy all files except prot.pdb to mcce_benchmarks_test\n",
    "\n",
    "\n",
    "# To have complete runs in canonical folder structure:\n",
    "\n",
    "# jmao benchamrk folder\n",
    "jmao_dir = Path.cwd().parent.parent.joinpath(\"benchmark\", \"e08_calc\") #-> like clean_pdbs\n",
    "print(f\"{jmao_dir = }\", jmao_dir.exists())\n",
    "\n",
    "#list_complete_runs(jmao_dir, like_clean_pdbs=True)\n",
    "#audit.cp_completed_runs(jmao_dir, test_dir)\n",
    "\n",
    "#audit.list_complete_runs(test_dir)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cleanup.prep_refset(benchmarks_dir, keep_files=files_retained)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "pkanalysis.collate_all_pkas(test_dir)\n",
    "pkanalysis.all_pkas_df(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import logging\n",
    "logger = logging.getLogger('cli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Test cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser, ArgumentError, RawDescriptionHelpFormatter, Namespace as argNamespace\n",
    "from mcce_benchmark import cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clilogr = cli.logger\n",
    "clilogr.hasHandlers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: \n",
      "bench_setup <+ 1 sub-command: pkdb_pdbs or user_pdbs or launch > <related args>\n",
      "\n",
      "Examples:\n",
      "1. pkdb_pdbs: Data & script setup using pkDBv1 pdbs:\n",
      "   - Minimal input: value for -bench_dir option:\n",
      "     >bench_setup pkdb_pdbs -bench_dir <folder path>\n",
      "\n",
      "   - Using non-default option(s) (then job_name is required!):\n",
      "     >bench_setup pkdb_pdbs -bench_dir <folder path> -d 8 -job_name <job_e8>\n",
      "\n",
      "2. user_pdbs: Data & script setup using user's pdb list:\n",
      "   - Minimal input: value for -bench_dir option, -pdb_list:\n",
      "     >bench_setup user_pdbs -bench_dir <folder path> -pdb_list <path to dir with pdb files OR file listing pdbs paths>\n",
      "\n",
      "   - Using non-default option(s) (then job_name is required! ):\n",
      "     >bench_setup user_pdbs -bench_dir <folder path> -pdb_list <path> -d 8 -job_name <job_e8>\n",
      "\n",
      "3. launch: Launch runs:\n",
      "   - Minimal input: value for -bench_dir option: IFF no non-default job_name & sentinel_file were passed in pkdb_pdbs\n",
      "     >bench_setup launch -bench_dir <folder path>\n",
      "\n",
      "   - Using non-default option(s):\n",
      "     >bench_setup launch -bench_dir <folder path> -n_batch <jobs to maintain>\n",
      "    Note: if changing the default sentinel_file=\"pk.out\" to, e.g. step2_out.pdb,\n",
      "        then the 'norun' script parameters for step 3 & 4 must be set accordingly:\n",
      "        >bench_setup launch -bench_dir <folder path> -sentinel_file step2_out.pdb --s3_norun --s4_norun\n",
      "\n",
      "Description:\n",
      "Launch a MCCE benchmarking job using either the curated structures from the pKaDBv1\n",
      "or the user's pdbs list.\n",
      "\n",
      "The main command is bench_setup along with one of 2 sub-commands:\n",
      "- Sub-command 1: pkdb_pdbs: setup the dataset and run script to run mcce steps 1 through 4;\n",
      "- Sub-command 2: user_pdbs: setup the user dataset and run script to run mcce steps 1 through 4;\n",
      "- Sub-command 3: launch: launch the automated scheduling of runs in batchs ;\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "bench_setup sub-commands:\n",
      "  Sub-commands of MCCE benchmarking cli.\n",
      "\n",
      "  {pkdb_pdbs,user_pdbs,launch}\n",
      "                        The 3 choices for the benchmarking process: 1) Setup\n",
      "                        pkdbv1 data & run-script: {SUB1} 2) Setup user data &\n",
      "                        run-script: {SUB2} 3) Schedule batch runs for mcce\n",
      "                        steps 1 through 4: {SUB3}\n",
      "    pkdb_pdbs           Sub-command for setting up <bench_dir>/RUNS folder &\n",
      "                        job_name_run.sh script, e.g.: >bench_setup pkdb_pdbs\n",
      "                        -bench_dir <folder name>\n",
      "    user_pdbs           Sub-command for setting up <bench_dir>/RUNS folder\n",
      "                        using user's pdb_list & job_name_run.sh script, e.g.:\n",
      "                        >bench_setup user_pdbs -bench_dir <folder name>\n",
      "    launch              Sub-command for launching the automated scheduling of\n",
      "                        runs in batches; e.g.: >bench_setup launch -bench_dir\n",
      "                        <folder name> -n_batch 15 Note: if provided, the value\n",
      "                        for the -job_name option must match the one used in\n",
      "                        `setup_job`.\n",
      "\n",
      "Post an issue for all errors and feature requests at:\n",
      "https://github.com/GunnerLab/MCCE_Benchmarking/issues\n"
     ]
    }
   ],
   "source": [
    "cli_parser = cli.bench_parser()\n",
    "\n",
    "cli_parser.print_help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test help msg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cli: None input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: \n",
      "bench_setup <+ 1 sub-command: pkdb_pdbs or user_pdbs or launch > <related args>\n",
      "\n",
      "Examples:\n",
      "1. pkdb_pdbs: Data & script setup using pkDBv1 pdbs:\n",
      "   - Minimal input: value for -bench_dir option:\n",
      "     >bench_setup pkdb_pdbs -bench_dir <folder path>\n",
      "\n",
      "   - Using non-default option(s) (then job_name is required!):\n",
      "     >bench_setup pkdb_pdbs -bench_dir <folder path> -d 8 -job_name <job_e8>\n",
      "\n",
      "2. user_pdbs: Data & script setup using user's pdb list:\n",
      "   - Minimal input: value for -bench_dir option, -pdb_list:\n",
      "     >bench_setup user_pdbs -bench_dir <folder path> -pdb_list <path to dir with pdb files OR file listing pdbs paths>\n",
      "\n",
      "   - Using non-default option(s) (then job_name is required! ):\n",
      "     >bench_setup user_pdbs -bench_dir <folder path> -pdb_list <path> -d 8 -job_name <job_e8>\n",
      "\n",
      "3. launch: Launch runs:\n",
      "   - Minimal input: value for -bench_dir option: IFF no non-default job_name & sentinel_file were passed in pkdb_pdbs\n",
      "     >bench_setup launch -bench_dir <folder path>\n",
      "\n",
      "   - Using non-default option(s):\n",
      "     >bench_setup launch -bench_dir <folder path> -n_batch <jobs to maintain>\n",
      "    Note: if changing the default sentinel_file=\"pk.out\" to, e.g. step2_out.pdb,\n",
      "        then the 'norun' script parameters for step 3 & 4 must be set accordingly:\n",
      "        >bench_setup launch -bench_dir <folder path> -sentinel_file step2_out.pdb --s3_norun --s4_norun\n",
      "bench_setup : error: argument subparser_name: invalid choice: '/home/cat/.local/share/jupyter/runtime/kernel-12f0225e-ca21-4f05-8fb4-48c596d1d2bc.json' (choose from 'pkdb_pdbs', 'user_pdbs', 'launch')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/argparse.py:1902\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1901\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1902\u001b[0m     namespace, args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1903\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ArgumentError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/argparse.py:2117\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   2116\u001b[0m \u001b[38;5;66;03m# consume any positionals following the last Optional\u001b[39;00m\n\u001b[0;32m-> 2117\u001b[0m stop_index \u001b[38;5;241m=\u001b[39m \u001b[43mconsume_positionals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2119\u001b[0m \u001b[38;5;66;03m# if we didn't consume all the argument strings, there were extras\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/argparse.py:2073\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.consume_positionals\u001b[0;34m(start_index)\u001b[0m\n\u001b[1;32m   2072\u001b[0m     start_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m arg_count\n\u001b[0;32m-> 2073\u001b[0m     \u001b[43mtake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[38;5;66;03m# slice off the Positionals that we just parsed and return the\u001b[39;00m\n\u001b[1;32m   2076\u001b[0m \u001b[38;5;66;03m# index at which the Positionals' string args stopped\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/argparse.py:1962\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.take_action\u001b[0;34m(action, argument_strings, option_string)\u001b[0m\n\u001b[1;32m   1961\u001b[0m seen_actions\u001b[38;5;241m.\u001b[39madd(action)\n\u001b[0;32m-> 1962\u001b[0m argument_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margument_strings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[38;5;66;03m# error if this argument is not allowed with other previously\u001b[39;00m\n\u001b[1;32m   1965\u001b[0m \u001b[38;5;66;03m# seen arguments, assuming that actions that use the default\u001b[39;00m\n\u001b[1;32m   1966\u001b[0m \u001b[38;5;66;03m# value don't really count as \"present\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/argparse.py:2506\u001b[0m, in \u001b[0;36mArgumentParser._get_values\u001b[0;34m(self, action, arg_strings)\u001b[0m\n\u001b[1;32m   2505\u001b[0m     value \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(action, v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m arg_strings]\n\u001b[0;32m-> 2506\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2508\u001b[0m \u001b[38;5;66;03m# SUPPRESS argument does not put anything in the namespace\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/argparse.py:2553\u001b[0m, in \u001b[0;36mArgumentParser._check_value\u001b[0;34m(self, action, value)\u001b[0m\n\u001b[1;32m   2552\u001b[0m msg \u001b[38;5;241m=\u001b[39m _(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid choice: \u001b[39m\u001b[38;5;132;01m%(value)r\u001b[39;00m\u001b[38;5;124m (choose from \u001b[39m\u001b[38;5;132;01m%(choices)s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2553\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ArgumentError(action, msg \u001b[38;5;241m%\u001b[39m args)\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument subparser_name: invalid choice: '/home/cat/.local/share/jupyter/runtime/kernel-12f0225e-ca21-4f05-8fb4-48c596d1d2bc.json' (choose from 'pkdb_pdbs', 'user_pdbs', 'launch')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcli\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbench_cli\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/MCCE_Benchmarking/mcce_benchmark/cli.py:524\u001b[0m, in \u001b[0;36mbench_cli\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    523\u001b[0m cli_parser \u001b[38;5;241m=\u001b[39m bench_parser()\n\u001b[0;32m--> 524\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mcli_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m args\u001b[38;5;241m.\u001b[39mfunc(args)\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/argparse.py:1869\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1869\u001b[0m     args, argv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1870\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m argv:\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/argparse.py:1904\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1903\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ArgumentError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 1904\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1905\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/argparse.py:2630\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2629\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprog\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprog, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m: message}\n\u001b[0;32m-> 2630\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%(prog)s\u001b[39;49;00m\u001b[38;5;124;43m: error: \u001b[39;49m\u001b[38;5;132;43;01m%(message)s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/argparse.py:2617\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2616\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_message(message, _sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m-> 2617\u001b[0m \u001b[43m_sys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2121\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2119\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2120\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2121\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2122\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/site-packages/IPython/core/ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/site-packages/IPython/core/ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/site-packages/IPython/core/ultratb.py:1448\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1450\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/site-packages/IPython/core/ultratb.py:1339\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1336\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/site-packages/IPython/core/ultratb.py:1186\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1179\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1184\u001b[0m ):\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1186\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1189\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/site-packages/IPython/core/ultratb.py:1076\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1074\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m   1075\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1076\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   1077\u001b[0m )\n\u001b[1;32m   1079\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1080\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mcbtest/lib/python3.11/site-packages/IPython/core/ultratb.py:1144\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1146\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "cmd = None\n",
    "cli.bench_cli(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: \n",
      "bench_setup <+ 1 sub-command: pkdb_pdbs or user_pdbs or launch > <related args>\n",
      "\n",
      "Examples:\n",
      "1. pkdb_pdbs: Data & script setup using pkDBv1 pdbs:\n",
      "   - Minimal input: value for -bench_dir option:\n",
      "     >bench_setup pkdb_pdbs -bench_dir <folder path>\n",
      "\n",
      "   - Using non-default option(s) (then job_name is required!):\n",
      "     >bench_setup pkdb_pdbs -bench_dir <folder path> -d 8 -job_name <job_e8>\n",
      "\n",
      "2. user_pdbs: Data & script setup using user's pdb list:\n",
      "   - Minimal input: value for -bench_dir option, -pdb_list:\n",
      "     >bench_setup user_pdbs -bench_dir <folder path> -pdb_list <path to dir with pdb files OR file listing pdbs paths>\n",
      "\n",
      "   - Using non-default option(s) (then job_name is required! ):\n",
      "     >bench_setup user_pdbs -bench_dir <folder path> -pdb_list <path> -d 8 -job_name <job_e8>\n",
      "\n",
      "3. launch: Launch runs:\n",
      "   - Minimal input: value for -bench_dir option: IFF no non-default job_name & sentinel_file were passed in pkdb_pdbs\n",
      "     >bench_setup launch -bench_dir <folder path>\n",
      "\n",
      "   - Using non-default option(s):\n",
      "     >bench_setup launch -bench_dir <folder path> -n_batch <jobs to maintain>\n",
      "    Note: if changing the default sentinel_file=\"pk.out\" to, e.g. step2_out.pdb,\n",
      "        then the 'norun' script parameters for step 3 & 4 must be set accordingly:\n",
      "        >bench_setup launch -bench_dir <folder path> -sentinel_file step2_out.pdb --s3_norun --s4_norun\n",
      "bench_setup : error: the following arguments are required: subparser_name\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/miniconda3/envs/mcbtest/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "cmd = []\n",
    "cli.bench_cli(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cli: 1 input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pkdb_pdbs']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: bench_setup <+ 1 sub-command: pkdb_pdbs or user_pdbs or launch > <related args>\n",
      "\n",
      "Examples:\n",
      "1. pkdb_pdbs: Data & script setup using pkDBv1 pdbs:\n",
      "   - Minimal input: value for -bench_dir option:\n",
      "     >bench_setup pkdb_pdbs -bench_dir <folder path>\n",
      "\n",
      "   - Using non-default option(s) (then job_name is required!):\n",
      "     >bench_setup pkdb_pdbs -bench_dir <folder path> -d 8 -job_name <job_e8>\n",
      "\n",
      "2. user_pdbs: Data & script setup using user's pdb list:\n",
      "   - Minimal input: value for -bench_dir option, -pdb_list:\n",
      "     >bench_setup user_pdbs -bench_dir <folder path> -pdb_list <path to dir with pdb files OR file listing pdbs paths>\n",
      "\n",
      "   - Using non-default option(s) (then job_name is required! ):\n",
      "     >bench_setup user_pdbs -bench_dir <folder path> -pdb_list <path> -d 8 -job_name <job_e8>\n",
      "\n",
      "3. launch: Launch runs:\n",
      "   - Minimal input: value for -bench_dir option: IFF no non-default job_name & sentinel_file were passed in pkdb_pdbs\n",
      "     >bench_setup launch -bench_dir <folder path>\n",
      "\n",
      "   - Using non-default option(s):\n",
      "     >bench_setup launch -bench_dir <folder path> -n_batch <jobs to maintain>\n",
      "    Note: if changing the default sentinel_file=\"pk.out\" to, e.g. step2_out.pdb,\n",
      "        then the 'norun' script parameters for step 3 & 4 must be set accordingly:\n",
      "        >bench_setup launch -bench_dir <folder path> -sentinel_file step2_out.pdb --s3_norun --s4_norun pkdb_pdbs\n",
      "       [-h] [-job_name JOB_NAME] [-sentinel_file SENTINEL_FILE] [-wet WET]\n",
      "       [--noter] [-u Key=Value] [-s1_norun S1_NORUN] [-s2_norun S2_NORUN]\n",
      "       [-s3_norun S3_NORUN] [-s4_norun S4_NORUN] [-d epsilon]\n",
      "       [-conf_making_level CONF_MAKING_LEVEL] [-c start end]\n",
      "       [-x /path/to/delphi] [-f tmp folder] [-p processes] [-r]\n",
      "       [-titr_type ph or eh] [-i initial ph/eh] [-interval interval]\n",
      "       [-n steps] [--ms] [--launch] -bench_dir BENCH_DIR [-n_pdbs N_PDBS]\n",
      "bench_setup <+ 1 sub-command: pkdb_pdbs or user_pdbs or launch > <related args>\n",
      "\n",
      "Examples:\n",
      "1. pkdb_pdbs: Data & script setup using pkDBv1 pdbs:\n",
      "   - Minimal input: value for -bench_dir option:\n",
      "     >bench_setup pkdb_pdbs -bench_dir <folder path>\n",
      "\n",
      "   - Using non-default option(s) (then job_name is required!):\n",
      "     >bench_setup pkdb_pdbs -bench_dir <folder path> -d 8 -job_name <job_e8>\n",
      "\n",
      "2. user_pdbs: Data & script setup using user's pdb list:\n",
      "   - Minimal input: value for -bench_dir option, -pdb_list:\n",
      "     >bench_setup user_pdbs -bench_dir <folder path> -pdb_list <path to dir with pdb files OR file listing pdbs paths>\n",
      "\n",
      "   - Using non-default option(s) (then job_name is required! ):\n",
      "     >bench_setup user_pdbs -bench_dir <folder path> -pdb_list <path> -d 8 -job_name <job_e8>\n",
      "\n",
      "3. launch: Launch runs:\n",
      "   - Minimal input: value for -bench_dir option: IFF no non-default job_name & sentinel_file were passed in pkdb_pdbs\n",
      "     >bench_setup launch -bench_dir <folder path>\n",
      "\n",
      "   - Using non-default option(s):\n",
      "     >bench_setup launch -bench_dir <folder path> -n_batch <jobs to maintain>\n",
      "    Note: if changing the default sentinel_file=\"pk.out\" to, e.g. step2_out.pdb,\n",
      "        then the 'norun' script parameters for step 3 & 4 must be set accordingly:\n",
      "        >bench_setup launch -bench_dir <folder path> -sentinel_file step2_out.pdb --s3_norun --s4_norun pkdb_pdbs: error: the following arguments are required: -bench_dir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "cmd = f\"{cli.SUB1}\".split()\n",
    "cmd\n",
    "cli.bench_cli(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: bench_setup <+ 1 sub-command: pkdb_pdbs or user_pdbs or launch > <related args>\n",
      "\n",
      "Examples:\n",
      "1. pkdb_pdbs: Data & script setup using pkDBv1 pdbs:\n",
      "   - Minimal input: value for -bench_dir option:\n",
      "     >bench_setup pkdb_pdbs -bench_dir <folder path>\n",
      "\n",
      "   - Using non-default option(s) (then job_name is required!):\n",
      "     >bench_setup pkdb_pdbs -bench_dir <folder path> -d 8 -job_name <job_e8>\n",
      "\n",
      "2. user_pdbs: Data & script setup using user's pdb list:\n",
      "   - Minimal input: value for -bench_dir option, -pdb_list:\n",
      "     >bench_setup user_pdbs -bench_dir <folder path> -pdb_list <path to dir with pdb files OR file listing pdbs paths>\n",
      "\n",
      "   - Using non-default option(s) (then job_name is required! ):\n",
      "     >bench_setup user_pdbs -bench_dir <folder path> -pdb_list <path> -d 8 -job_name <job_e8>\n",
      "\n",
      "3. launch: Launch runs:\n",
      "   - Minimal input: value for -bench_dir option: IFF no non-default job_name & sentinel_file were passed in pkdb_pdbs\n",
      "     >bench_setup launch -bench_dir <folder path>\n",
      "\n",
      "   - Using non-default option(s):\n",
      "     >bench_setup launch -bench_dir <folder path> -n_batch <jobs to maintain>\n",
      "    Note: if changing the default sentinel_file=\"pk.out\" to, e.g. step2_out.pdb,\n",
      "        then the 'norun' script parameters for step 3 & 4 must be set accordingly:\n",
      "        >bench_setup launch -bench_dir <folder path> -sentinel_file step2_out.pdb --s3_norun --s4_norun user_pdbs\n",
      "       [-h] [-job_name JOB_NAME] [-sentinel_file SENTINEL_FILE] [-wet WET]\n",
      "       [--noter] [-u Key=Value] [-s1_norun S1_NORUN] [-s2_norun S2_NORUN]\n",
      "       [-s3_norun S3_NORUN] [-s4_norun S4_NORUN] [-d epsilon]\n",
      "       [-conf_making_level CONF_MAKING_LEVEL] [-c start end]\n",
      "       [-x /path/to/delphi] [-f tmp folder] [-p processes] [-r]\n",
      "       [-titr_type ph or eh] [-i initial ph/eh] [-interval interval]\n",
      "       [-n steps] [--ms] [--launch] -bench_dir BENCH_DIR\n",
      "       [-pdbs_list PDBS_LIST]\n",
      "bench_setup <+ 1 sub-command: pkdb_pdbs or user_pdbs or launch > <related args>\n",
      "\n",
      "Examples:\n",
      "1. pkdb_pdbs: Data & script setup using pkDBv1 pdbs:\n",
      "   - Minimal input: value for -bench_dir option:\n",
      "     >bench_setup pkdb_pdbs -bench_dir <folder path>\n",
      "\n",
      "   - Using non-default option(s) (then job_name is required!):\n",
      "     >bench_setup pkdb_pdbs -bench_dir <folder path> -d 8 -job_name <job_e8>\n",
      "\n",
      "2. user_pdbs: Data & script setup using user's pdb list:\n",
      "   - Minimal input: value for -bench_dir option, -pdb_list:\n",
      "     >bench_setup user_pdbs -bench_dir <folder path> -pdb_list <path to dir with pdb files OR file listing pdbs paths>\n",
      "\n",
      "   - Using non-default option(s) (then job_name is required! ):\n",
      "     >bench_setup user_pdbs -bench_dir <folder path> -pdb_list <path> -d 8 -job_name <job_e8>\n",
      "\n",
      "3. launch: Launch runs:\n",
      "   - Minimal input: value for -bench_dir option: IFF no non-default job_name & sentinel_file were passed in pkdb_pdbs\n",
      "     >bench_setup launch -bench_dir <folder path>\n",
      "\n",
      "   - Using non-default option(s):\n",
      "     >bench_setup launch -bench_dir <folder path> -n_batch <jobs to maintain>\n",
      "    Note: if changing the default sentinel_file=\"pk.out\" to, e.g. step2_out.pdb,\n",
      "        then the 'norun' script parameters for step 3 & 4 must be set accordingly:\n",
      "        >bench_setup launch -bench_dir <folder path> -sentinel_file step2_out.pdb --s3_norun --s4_norun user_pdbs: error: the following arguments are required: -bench_dir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "cmd = f\"{cli.SUB2}\".split() #benchmarks_dir {benchmarks_dir} -job_name {job} -d 8\".split()\n",
    "\n",
    "cli.bench_cli(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cli: 2 with help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pkdb_pdbs', '-h']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: bench_setup <+ 1 sub-command: pkdb_pdbs or user_pdbs or launch > <related args>\n",
      "\n",
      "Examples:\n",
      "1. pkdb_pdbs: Data & script setup using pkDBv1 pdbs:\n",
      "   - Minimal input: value for -bench_dir option:\n",
      "     >bench_setup pkdb_pdbs -bench_dir <folder path>\n",
      "\n",
      "   - Using non-default option(s) (then job_name is required!):\n",
      "     >bench_setup pkdb_pdbs -bench_dir <folder path> -d 8 -job_name <job_e8>\n",
      "\n",
      "2. user_pdbs: Data & script setup using user's pdb list:\n",
      "   - Minimal input: value for -bench_dir option, -pdb_list:\n",
      "     >bench_setup user_pdbs -bench_dir <folder path> -pdb_list <path to dir with pdb files OR file listing pdbs paths>\n",
      "\n",
      "   - Using non-default option(s) (then job_name is required! ):\n",
      "     >bench_setup user_pdbs -bench_dir <folder path> -pdb_list <path> -d 8 -job_name <job_e8>\n",
      "\n",
      "3. launch: Launch runs:\n",
      "   - Minimal input: value for -bench_dir option: IFF no non-default job_name & sentinel_file were passed in pkdb_pdbs\n",
      "     >bench_setup launch -bench_dir <folder path>\n",
      "\n",
      "   - Using non-default option(s):\n",
      "     >bench_setup launch -bench_dir <folder path> -n_batch <jobs to maintain>\n",
      "    Note: if changing the default sentinel_file=\"pk.out\" to, e.g. step2_out.pdb,\n",
      "        then the 'norun' script parameters for step 3 & 4 must be set accordingly:\n",
      "        >bench_setup launch -bench_dir <folder path> -sentinel_file step2_out.pdb --s3_norun --s4_norun pkdb_pdbs\n",
      "       [-h] [-job_name JOB_NAME] [-sentinel_file SENTINEL_FILE] [-wet WET]\n",
      "       [--noter] [-u Key=Value] [-s1_norun S1_NORUN] [-s2_norun S2_NORUN]\n",
      "       [-s3_norun S3_NORUN] [-s4_norun S4_NORUN] [-d epsilon]\n",
      "       [-conf_making_level CONF_MAKING_LEVEL] [-c start end]\n",
      "       [-x /path/to/delphi] [-f tmp folder] [-p processes] [-r]\n",
      "       [-titr_type ph or eh] [-i initial ph/eh] [-interval interval]\n",
      "       [-n steps] [--ms] [--launch] -bench_dir BENCH_DIR [-n_pdbs N_PDBS]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -job_name JOB_NAME    The descriptive name, devoid of spaces, for the\n",
      "                        current job (don't make it too long!); required. This\n",
      "                        job_name is used to identify the shell script in\n",
      "                        'bench_dir' that launches the MCCE simulation in\n",
      "                        'bench_dir'/RUNS_DIR subfolders; default: default_run.\n",
      "  -sentinel_file SENTINEL_FILE\n",
      "                        File whose existence signals a completed step; When\n",
      "                        running all 4 MCCE steps (default), this file is\n",
      "                        'pK.out', while when running only the first 2 [future\n",
      "                        implementation], this file is 'step2_out.pdb';\n",
      "                        default: pK.out.\n",
      "  -wet WET              Keep water molecules.\n",
      "  --noter               Do not label terminal residues (for making ftpl).\n",
      "  -u Key=Value          User selected, comma-separated KEY=var pairs from\n",
      "                        run.prm; e.g.: -u HOME_MCCE=/path/to/mcce_home,H2O_SAS\n",
      "                        CUTOFF=0.05,EXTRA=./extra.tpl; default: . Note: No\n",
      "                        space after a comma!\n",
      "  -s1_norun S1_NORUN    Create run.prm without running step 1.\n",
      "  -s2_norun S2_NORUN    Create run.prm without running step 2.\n",
      "  -s3_norun S3_NORUN    Create run.prm without running step 3.\n",
      "  -s4_norun S4_NORUN    Create run.prm without running step 4.\n",
      "  -d epsilon            protein dielectric constant for delphi; 4.0.\n",
      "  -conf_making_level CONF_MAKING_LEVEL\n",
      "                        conformer level 1: quick, 2: medium, 3: comprehensive;\n",
      "                        default: 1.\n",
      "  -c start end          Starting and ending conformer; default: [1, 99999].\n",
      "  -x /path/to/delphi    Delphi executable location; default: delphi.\n",
      "  -f tmp folder         Delphi temporary folder; default: /tmp.\n",
      "  -p processes          Number of processes to use; default: 1.\n",
      "  -r                    Refresh opp files and head3.lst without running Delphi\n",
      "  -titr_type ph or eh   Titration type, pH or Eh; default: ph.\n",
      "  -i initial ph/eh      Initial pH/Eh of titration; default: 0.0.\n",
      "  -interval interval    Titration interval in pJ or mV; default: 1.0.\n",
      "  -n steps              number of steps of titration; default: 15.\n",
      "  --ms                  Enable microstate output\n",
      "  --launch              Schedule the job right away (no chance of inspecting\n",
      "                        <job_name>.sh!)\n",
      "  -bench_dir BENCH_DIR  The user's choice of directory for setting up the\n",
      "                        benchmarking job(s); this is where the RUNS folder\n",
      "                        reside. The directory is created if it does not exists\n",
      "                        unless this cli is called within that directory.\n",
      "  -n_pdbs N_PDBS        The number of curated pdbs to setup for the\n",
      "                        benchmarking job; max=default: 120.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "cmd = f\"{cli.SUB1} -h\".split() #benchmarks_dir {benchmarks_dir} -job_name {job} -d 8\".split()\n",
    "cmd\n",
    "#args = cli_parser.parse_args(cmd)\n",
    "\n",
    "cli.bench_cli(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cli: setup with n_pdbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcce_benchmark import custom_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pkdb_pdbs', '-bench_dir', '../foo_dir', '-n_pdbs', '2']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ben_dir = \"../foo_dir\"\n",
    "cmd = f\"{cli.SUB1} -bench_dir {ben_dir} -n_pdbs 2\".split() # -job_name {job} -d 8\".split()\n",
    "cmd\n",
    "args = cli_parser.parse_args(cmd)\n",
    "\n",
    "all_default = custom_sh.all_opts_are_defaults(args)\n",
    "all_default\n",
    "\n",
    "cli.bench_cli(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(subparser_name='pkdb_pdbs', job_name='default_run', sentinel_file='pK.out', wet=False, noter=False, u='', s1_norun=False, s2_norun=False, s3_norun=False, s4_norun=False, d=4.0, conf_making_level=1, c=[1, 99999], x='delphi', f='/tmp', p=1, r=False, titr_type='ph', i=0.0, interval=1.0, n=15, ms=False, launch=False, bench_dir=PosixPath('/home/cat/projects/MCCE_Benchmarking/foo_dir'), n_pdbs=2, func=<function bench_job_setup at 0x7f0e4200af20>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'wet': False,\n",
       " 'noter': False,\n",
       " 'u': '',\n",
       " 's1_norun': False,\n",
       " 's2_norun': False,\n",
       " 's3_norun': False,\n",
       " 's4_norun': False,\n",
       " 'd': 4.0,\n",
       " 'conf_making_level': 1,\n",
       " 'c': [1, 99999],\n",
       " 'x': 'delphi',\n",
       " 'f': '/tmp',\n",
       " 'p': 1,\n",
       " 'r': False,\n",
       " 'titr_type': 'ph',\n",
       " 'i': 0.0,\n",
       " 'interval': 1.0,\n",
       " 'n': 15,\n",
       " 'ms': False,\n",
       " 'launch': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False at: launch\n"
     ]
    }
   ],
   "source": [
    "args\n",
    "\n",
    "# holds mcce options only\n",
    "d_sh_args = custom_sh.cli_args_to_dict(args)\n",
    "\n",
    "d_sh_args\n",
    "\n",
    "is_default = True\n",
    "for opt in d_sh_args:\n",
    "    is_default = (is_default\n",
    "                  and d_sh_args[opt] == custom_sh.all_default_opts.get(opt)\n",
    "    )\n",
    "    if not is_default:  # done\n",
    "        print(\"False at:\", opt)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['launch_job', '-benchmarks_dir', '../foo_dir']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: mcce_benchmark.cli, bench_launch_batch:\n",
      "\tbench_expl_pkas args:\n",
      "{'subparser_name': 'launch_job',\n",
      " 'benchmarks_dir': PosixPath('/home/cat/projects/MCCE_Benchmarking/notebooks/foo_dir'),\n",
      " 'job_name': 'default_run',\n",
      " 'n_active': 10,\n",
      " 'sentinel_file': 'pK.out',\n",
      " 'func': <function mcce_benchmark.cli.bench_launch_batch(args: argparse.Namespace) -> None>}\n",
      "\n",
      "[INFO]: mcce_benchmark.cli, bench_launch_batch:\n",
      "\tScript contents prior to launch:\n",
      "#!/bin/bash\n",
      "\n",
      "step1.py --dry prot.pdb\n",
      "step2.py -d 4\n",
      "step3.py -d 4\n",
      "step4.py --xts\n",
      "\n",
      "sleep 10\n",
      "\n",
      "[INFO]: mcce_benchmark.cli, bench_launch_batch:\n",
      "\tSubmiting batch of jobs.\n",
      "[INFO]: mcce_benchmark.scheduling, create_cron_sh:\n",
      "\tCreated script for crontab 'crontab_default_run_sh' in /home/cat/projects/MCCE_Benchmarking/notebooks/foo_dir\n",
      "\n",
      "[INFO]: mcce_benchmark.scheduling, schedule_job:\n",
      "\tCreated the bash script for crontab.\n",
      "[INFO]: mcce_benchmark.scheduling, create_crontab:\n",
      "\tCrontab text:\n",
      "#Scheduled from bench_launchjob\n",
      "* * * * * /home/cat/projects/MCCE_Benchmarking/notebooks/foo_dir/crontab_default_run_sh > /home/cat/projects/MCCE_Benchmarking/notebooks/foo_dir/cron_default_run.log 2>&1\n",
      "\n",
      "[INFO]: mcce_benchmark.scheduling, create_crontab:\n",
      "\tUser's cron jobs, if any:\n",
      "[INFO]: mcce_benchmark.scheduling, create_crontab:\n",
      "\t# Scheduled from mccebench\n",
      "* * * * * cd /home/cat/projects/mcce_benchmarks && /home/cat/miniconda3/envs/mce/bin/mccebench_launchjob -benchmarks_dir /home/cat/projects/mcce_benchmarks -job_name foo -n_active 4 -sentinel_file step2_out.pdb\n",
      "\n",
      "[INFO]: mcce_benchmark.scheduling, schedule_job:\n",
      "\tScheduled batch submission with crontab every minute.\n",
      "[INFO]: mcce_benchmark.cli, log_mcce_version:\n",
      "\tMCCE Version(s) found in run.log files:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cmd = f\"{cli.SUB2} -bench_dir {ben_dir}\".split()\n",
    "cmd\n",
    "\n",
    "cli.bench_cli(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: mcce_benchmark.cli, <module>:\n",
      "\t\n",
      "START\n",
      "----------------------------------------------------------------------\n",
      "2024-02-28 13:41:41 - USER = 'cat' - User envir: mce\n",
      "APP VER: (0, 1, 0, 'dev5', 'g2095b87.d20240226')\n",
      "APP DEFAULTS:\n",
      "Globals: MCCE_EPS = 4; N_ACTIVE = 10\n",
      "Default resource names:\n",
      "DEFAULT_DIR = 'mcce_benchmarks' : default benchmarking folder name\n",
      "BENCH.CLEAN_PDBS = 'clean_pdbs' : fixed\n",
      "BENCH.Q_BOOK = 'book.txt' : jobs bookkeeping file\n",
      "BENCH.DEFAULT_JOB = 'default_run' (-> default_run.sh script in clean_pdbs/)\n",
      "BENCH.BENCH_PARSE_E4 = PosixPath('/home/cat/projects/MCCE_Benchmarking/mcce_benchmark/data/refsets/parse.e4') : Current reference set\n",
      "N_PDBS = 120 : number of pdbs in the dataset\n",
      "Default analysis output file names (fixed):\n",
      "OUT_FILES.MATCHED_PKAS_FILE.name = 'MATCHED_PKAS_FILE'\n",
      "OUT_FILES.ALL_PKAS_FILE.name = 'ALL_PKAS_FILE'\n",
      "OUT_FILES.CONF_COUNTS.name = 'CONF_COUNTS'\n",
      "OUT_FILES.RES_COUNTS.name = 'RES_COUNTS'\n",
      "OUT_FILES.RUN_TIMES.name = 'RUN_TIMES'\n",
      "OUT_FILES.CONFS_PER_RES.name = 'CONFS_PER_RES'\n",
      "OUT_FILES.CONFS_THRUPUT.name = 'CONFS_THRUPUT'\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mcce_benchmark import scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CONDA_PATH',\n",
       " 'CRON_COMMENT',\n",
       " 'CRON_SH_PREFIX',\n",
       " 'CronTab',\n",
       " 'ENTRY_POINTS',\n",
       " 'Path',\n",
       " 'Pathok',\n",
       " 'USER',\n",
       " 'USER_ENV',\n",
       " 'USER_PRFX',\n",
       " 'Union',\n",
       " 'argNamespace',\n",
       " 'create_cron_sh',\n",
       " 'create_crontab',\n",
       " 'create_crontab_old',\n",
       " 'logger',\n",
       " 'logging',\n",
       " 'make_executable',\n",
       " 'schedule_job',\n",
       " 'shutil',\n",
       " 'subprocess',\n",
       " 'subprocess_run',\n",
       " 'sys']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdir(scheduling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/cat/miniconda3/envs/mce', 'mce', '/home/cat/miniconda3/condabin/conda')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'mccebench_launchjob'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/cat/projects/mcce_benchmarks_test')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_PRFX, USER_ENV, CONDA_PATH\n",
    "ENTRY_POINTS[\"launch\"]\n",
    "benchmarks_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cron_txt = scheduling.create_single_crontab( benchmarks_dir, job, debug=True)\n",
    "print(cron_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Test cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/cat/projects/mcce_benchmarks_test/clean_pdbs/norun_foo.sh')"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#!/bin/bash\n",
      "\n",
      "step1.py prot.pdb --norun\n"
     ]
    }
   ],
   "source": [
    "job = \"norun_foo\"\n",
    "custom_sh.write_run_script_from_template(benchmarks_dir, job,\n",
    "                                                    script_template = ScriptChoices.NORUN,\n",
    "                                                    job_args = None)\n",
    "sh_path = benchmarks_dir.joinpath(BENCH.CLEAN_PDBS, f\"{job}.sh\")\n",
    "sh_path.exists()\n",
    "sh_path\n",
    "!cat {sh_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " #!/bin/bash\n",
      "\n",
      " step1.py prot.pdb --dry -d 8.0\n",
      " step2.py -d 8.0\n",
      " step3.py -d 8.0\n",
      " step4.py --xts \n",
      "\n",
      " sleep 10\n"
     ]
    }
   ],
   "source": [
    "!cat {sh_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_default_script = check_steps_opt_defaults(args)\n",
    "use_default_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " #!/bin/bash\n",
      "\n",
      " step1.py prot.pdb --dry -d 8.0\n",
      " step2.py -d 8.0\n",
      " step3.py -d 8.0\n",
      " step4.py --xts \n",
      "\n",
      " sleep 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = populate_custom_template(args)\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mcbtest]",
   "language": "python",
   "name": "conda-env-mcbtest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
